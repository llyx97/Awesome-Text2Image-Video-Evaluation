# Awesome-Text2Image-Video-Evaluation
Summary of text-to-image/video synthesis evaluation papers


### Text-Image/Video Alignment Metrics
+ VPEval
  + [Visual Programming for Text-to-Image Generation and Evaluation](https://arxiv.org/abs/2305.15328) (May., 2023)  
    [![Star](https://img.shields.io/github/stars/aszala/VPEval.svg?style=social&label=Star)](https://github.com/aszala/VPEval)
    [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2305.15328)
    [![Website](https://img.shields.io/badge/Website-9cf)](https://vp-t2i.github.io/)
    
+ VQ^2
  + [What You See is What You Read? Improving Text-Image Alignment Evaluation](https://arxiv.org/abs/2305.10400) (May., 2023)  
    [![Star](https://img.shields.io/github/stars/yonatanbitton/wysiwyr.svg?style=social&label=Star)](https://github.com/yonatanbitton/wysiwyr)
    [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2305.10400)
    
+ LLMScore
  + [LLMScore: Unveiling the Power of Large Language Models in Text-to-Image Synthesis Evaluation](https://arxiv.org/abs/2305.11116) (May., 2023)  
    [![Star](https://img.shields.io/github/stars/Yushi-Hu/tifa.svg?style=social&label=Star)](https://github.com/yujielu10/llmscore)
    [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2305.11116)
    
+ TIFA
  + [TIFA: Accurate and Interpretable Text-to-Image Faithfulness Evaluation with Question Answering](https://arxiv.org/abs/2303.11897) (Mar., 2023)  
    [![Star](https://img.shields.io/github/stars/Yushi-Hu/tifa.svg?style=social&label=Star)](https://github.com/Yushi-Hu/tifa)
    [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2303.11897)
    [![Website](https://img.shields.io/badge/Website-9cf)](https://tifa-benchmark.github.io/)
    
+ CLIPScore
  + [CLIPScore: A Reference-free Evaluation Metric for Image Captioning](https://arxiv.org/abs/2104.08718) (Apr., 2021)  
    [![Star](https://img.shields.io/github/stars/jmhessel/clipscore.svg?style=social&label=Star)](https://github.com/jmhessel/clipscore)
    [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2104.08718)

### Image/Video Quality Metrics
+ [Exploring Video Quality Assessment on User Generated Contents from Aesthetic and Technical Perspectives](https://arxiv.org/abs/2211.04894) (Nov., 2022)  
  [![Star](https://img.shields.io/github/stars/vqassessment/dover.svg?style=social&label=Star)](https://github.com/vqassessment/dover)
  [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2211.04894)

+ Fréchet Inception Distance (FID)
  + [On Aliased Resizing and Surprising Subtleties in GAN Evaluation](https://arxiv.org/abs/2104.11222) (Apr., 2021)  
    [![Star](https://img.shields.io/github/stars/GaParmar/clean-fid.svg?style=social&label=Star)](https://github.com/GaParmar/clean-fid)
    [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2104.11222)
    [![Website](https://img.shields.io/badge/Website-9cf)](https://www.cs.cmu.edu/~clean-fid/)

  + [FID score for PyTorch](https://github.com/mseitzer/pytorch-fid)  
    [![Star](https://img.shields.io/github/stars/mseitzer/pytorch-fid.svg?style=social&label=Star)](https://github.com/mseitzer/pytorch-fid)

  + [GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium](https://arxiv.org/abs/1706.08500) (Jun., 2017)  
    [![Star](https://img.shields.io/github/stars/bioinf-jku/TTUR.svg?style=social&label=Star)](https://github.com/bioinf-jku/TTUR) 
    [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/1706.08500)
  
+ Fréchet Video Distance (FVD)
  + [StyleGAN-V: A Continuous Video Generator with the Price, Image Quality and Perks of StyleGAN2](https://arxiv.org/abs/2112.14683) (Dec., 2021)  
    [![Star](https://img.shields.io/github/stars/universome/stylegan-v.svg?style=social&label=Star)](https://github.com/universome/stylegan-v)
    [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2112.14683)
    [![Website](https://img.shields.io/badge/Website-9cf)](https://universome.github.io/stylegan-v)
  + [Towards Accurate Generative Models of Video: A New Metric & Challenges](https://arxiv.org/abs/1812.01717) (Dec., 2018)  
    [code](https://github.com/google-research/google-research/tree/master/frechet_video_distance) 
    [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/1812.01717)

+ Inception Score (IS)
  + [Improved Techniques for Training GANs](https://arxiv.org/abs/1606.03498) (Jun., 2016)  
    [![Star](https://img.shields.io/github/stars/openai/improved-gan.svg?style=social&label=Star)](https://github.com/openai/improved-gan) 
    [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/1606.03498)



### Benchmarks
+ FETV
  + [FETV: A Benchmark for Fine-Grained Evaluation of Open-Domain Text-to-Video Generation](https://neurips.cc/virtual/2023/poster/73413)  
    [![Star](https://img.shields.io/github/stars/llyx97/FETV.svg?style=social&label=Star)](https://github.com/llyx97/FETV)

+ EvalCrafter
  + [Benchmarking and Evaluating Large Video Generation Models](https://arxiv.org/abs/2310.11440) (Oct., 2023)  
    [![Star](https://img.shields.io/github/stars/EvalCrafter/EvalCrafter.svg?style=social&label=Star)](https://github.com/EvalCrafter/EvalCrafter)
    [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2310.11440)
    [![Website](https://img.shields.io/badge/Website-9cf)](https://evalcrafter.github.io/)

+ TIFA
  + [TIFA: Accurate and Interpretable Text-to-Image Faithfulness Evaluation with Question Answering](https://arxiv.org/abs/2303.11897) (Mar., 2023)  
    [![Star](https://img.shields.io/github/stars/Yushi-Hu/tifa.svg?style=social&label=Star)](https://github.com/Yushi-Hu/tifa)
    [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2303.11897)
    [![Website](https://img.shields.io/badge/Website-9cf)](https://tifa-benchmark.github.io/)
    
+ PartiPrompts
  + [Scaling Autoregressive Models for Content-Rich Text-to-Image Generation](https://arxiv.org/abs/2206.10789) (Jun., 2022)  
    [![Star](https://img.shields.io/github/stars/google-research/parti.svg?style=social&label=Star)](https://github.com/google-research/parti)
    [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2206.10789)
    [![Website](https://img.shields.io/badge/Website-9cf)](https://sites.research.google/parti/)
    
+ DrawBench
  + [Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding](https://arxiv.org/abs/2205.11487) (May., 2022)  
    [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2205.11487)
    [![Website](https://img.shields.io/badge/Website-9cf)](https://imagen.research.google/)
    [data](https://docs.google.com/spreadsheets/d/1y7nAbmR4FREi6npB1u-Bo3GFdwdOPYJc617rBOxIRHY/edit#gid=0)

+ PaintSkills
  + [DALL-Eval: Probing the Reasoning Skills and Social Biases of Text-to-Image Generation Models](https://arxiv.org/abs/2202.04053) (Feb., 2022)
    [![Star](https://img.shields.io/github/stars/j-min/dalleval.svg?style=social&label=Star)](https://github.com/j-min/dalleval)
    [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/2205.11487)
    
+ MSR-VTT
  + [MSR-VTT: A large video description dataset for bridging video and language.](https://www.microsoft.com/en-us/research/publication/msr-vtt-a-large-video-description-dataset-for-bridging-video-and-language/) (Jun., 2016)  
    [![Website](https://img.shields.io/badge/Website-9cf)](https://www.microsoft.com/en-us/research/publication/msr-vtt-a-large-video-description-dataset-for-bridging-video-and-language/)
    [data](https://cove.thecvf.com/datasets/839)
    
+ UCF101
  + [UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild](https://arxiv.org/abs/1212.0402) (Dec., 2012)  
    [![arXiv](https://img.shields.io/badge/arXiv-b31b1b.svg)](https://arxiv.org/abs/1212.0402)
    [![Website](https://img.shields.io/badge/Website-9cf)](https://www.crcv.ucf.edu/data/UCF101.php)
